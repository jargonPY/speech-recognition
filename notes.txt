*-------- venv setup -------*
1. python3 -m venv .venv
2. source .venv/bin/activate
3. pip freeze > requirements.txt
4. pip install -r requirements.txt

*-------- Ideas ------------*
    1. Different preprocessing techniques during training (data augmentation)
    2. Ensembles
    3. JSON file should maintain a list of model test scores so that it can be easily
       to run best or 10 best
        - ModelsMetaData needs a method that will be called from test() to update this variable

*-------- Questions --------*
    1. when saving model:
        - save best or save per epoch (if best overwrite old files)?
        - what other data to keep track of (number of total epochs, train/val history)?
            - this is also returned as part of the history object
    2. how much of this is necessary before beginning proper training?
    3. How to implement for Jupyter notebooks?

*-------- To Do ------------*
    1. log preprocessed data and incorporate data validation 
        - need to make sure preprocessing is performed as expected
    2. develop a global logging system with debug/test and training modes
    3. build visualization tools for audio data
    4. allow for a global variable that indicates debugging, which will automatically ensure
       smaller batch sizes and faster run times
        - global variable or environment variable?
    5. metrics and visualizations for comparing models
    6. look into methods for searching the space of model parameters

*-------- Next Steps -------*
1. function to upload/download weight files to the cloud
  - read permissions for everyone, write permissions with credentials
2. logs to track CPU/GPU usage + monitoring performace during training
  - done throguh tensorflow
  - can programmatically access the logs
3. plotting functionality
4. start training!!!